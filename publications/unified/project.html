<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta http-equiv="Content-Language" content="zh-cn" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>A Unified Spatial-Angular Structured Light for Single-View Acquisition of Shape and Reflectance</title>
<link href="../../gly.css" rel="stylesheet" type="text/css">

<style type="text/css">
.style3 {
				font-family: Georgia, Times, serif;
				font-size: 16pt;
				font-style: normal;
				color: #000000;
}
.style7 {
				font-family: Georgia, Times, serif;
				font-size: 12pt;
				font-style: normal;
				color: #000000;
}
.style8 {
				text-align: center;
}
.style9 {
				/* fixed width */
	margin: 0 auto;
				padding: 30px;
				width: 720px;
				text-align: center;
				position: relative;
				font-family: Georgia, Times, serif;
				font-size: 10pt;
				font-style: normal;
				font-weight: normal;
				color: rgb(00,00,00);/*#000000;*/;
				background-color: rgb(255,255,255);
				-moz-border-radius: 15px;
				border-radius: 15px;
				-moz-box-shadow: 4px 4px 6px #888;
				-webkit-box-shadow: 4px 4px 6px #888;
				box-shadow: 4px 4px 6px #888;
}
.style10 {
				text-align: left;
}
.style11 {
				font-family: Georgia, Times, serif;
				font-size: 12pt;
				font-style: normal;
				font-weight: normal;
				color: #000000;
}
.style12 {
				font-family: Georgia, Times, serif;
				font-size: 10pt;
				font-style: normal;
				color: #000000;
}
.style13 {
				text-align: center;
				font-family: Georgia, Times, serif;
				font-size: 12pt;
				font-style: normal;
				color: #000000;
}
.style14 {
				font-family: Georgia, Times, serif;
				font-style: normal;
				font-weight: bold;
				color: #000000;
}
</style>

</head>

<body>
<div class="style9">
<div class="style8">
<span class="style3">A Unified Spatial-Angular Structured Light for Single-View Acquisition of Shape and Reflectance<br />
</span>
<br />
<span class="style7">
	Xianmin Xu, 
	Yuxin Lin, 
	Haoyang Zhou, 
	Chong Zeng, 
	Yaxin Yu,
	<a href="http://kunzhou.net/">Kun Zhou</a> and
	<a href="http://hongzhiwu.com/">Hongzhi Wu</a>
</span><br />
<span class="text"><br />
</span><span class="style11">CVPR 2023.<br />
Patent Pending.<br />
<br />
<br />
<iframe class="papericon" width="700" height="394" src="https://www.youtube.com/embed/O4IR6BKqzto" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br />
<br />
				<img src="paper01.jpg" width="135" class="papericon">
				<img src="paper02.jpg" width="135" class="papericon">
				<img src="paper03.jpg" width="135" class="papericon">
				<img src="paper04.jpg" width="135" class="papericon">
				<img src="paper05.jpg" width="135" class="papericon">
				<img src="paper06.jpg" width="135" class="papericon">
				<img src="paper07.jpg" width="135" class="papericon">
				<img src="paper08.jpg" width="135" class="papericon">
				<img src="paper09.jpg" width="135" class="papericon">
				<img src="paper10.jpg" width="135" class="papericon">
<br />
</span>
<div class="style10">
				<span class="textsectionheader2"><br />
				Abstract</span><span class="text"><br />
				<br />
We propose a unified structured light, consisting of an LED array and an LCD mask, for high-quality acquisition of both shape and reflectance from a single view. For geometry, one LED projects a set of learned mask patterns to accurately encode spatial information; the decoded results from multiple LEDs are then aggregated to produce a final depth map. For appearance, learned light patterns are cast through a transparent mask to efficiently probe angularly- varying reflectance. Per-point BRDF parameters are differentiably optimized with respect to corresponding measurements, and stored in texture maps as the final reflectance. We establish a differentiable pipeline for the joint capture to automatically optimize both the mask and light patterns to- wards optimal acquisition quality. The effectiveness of our light is demonstrated with a wide variety of physical objects. Our results compare favorably with state-of-the-art techniques.				
				<br />
				</span><br />
				<hr /><br />
				<span class="textsectionheader2">Downloads
				</span>
				<br />
				<br />
				Paper <a href="unified.pdf">[.PDF, 7.9MB]</a><br />
				<br />
				Supplemental Material <a href="supplemental.pdf">[.PDF, 0.8MB]</a><br />
				<br />
				Video [<a href="https://youtu.be/O4IR6BKqzto">Youtube</a>/<a href="https://www.bilibili.com/video/BV1Gs4y1d7qq/">Bilibili</a>] <br />
				<br />
				Bibtex [.BIB] <br />
				<br />
				</span> 
				<hr />				
<br />
<br />
<div class="style13">
<a href="../../index.html">Back</a></div>
</div>
</body>

</html>
